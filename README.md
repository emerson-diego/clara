# LEIA: Dataset para Classifica√ß√£o de Conformidade Documental

[![License: CC BY-SA 4.0](https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-sa/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## üìã Vis√£o Geral

O **LEIA** (*Legal-Administrative Enrichment and Information Annotation Dataset*) √© um dataset p√∫blico e balanceado para classifica√ß√£o de conformidade documental no setor p√∫blico brasileiro. O projeto aborda o delicado equil√≠brio entre transpar√™ncia (Lei de Acesso √† Informa√ß√£o - LAI) e prote√ß√£o de dados (Lei Geral de Prote√ß√£o de Dados - LGPD).

### üéØ Objetivos

- Fornecer um dataset balanceado para treinamento de modelos de IA
- Facilitar a automa√ß√£o da classifica√ß√£o documental no setor p√∫blico
- Garantir total privacidade atrav√©s de dados sint√©ticos
- Fomentar pesquisas em Processamento de Linguagem Natural (PLN)

### üîë Caracter√≠sticas Principais

- **6.000 registros** balanceados (2.000 por classe)
- **3 classes de acesso**: Sigiloso (0), Interno (1), P√∫blico (2)
- **100% dados sint√©ticos** para prote√ß√£o de privacidade
- **Compat√≠vel** com modelos Transformer (BERT, RoBERTa, etc.)
- **Valida√ß√£o humana** em 10% dos registros

## üìä Estrutura do Dataset

### Classes de Classifica√ß√£o

| Classe | C√≥digo | Descri√ß√£o |
|--------|--------|-----------|
| **Sigiloso** | 0 | Acesso restrito, informa√ß√µes confidenciais |
| **Interno** | 1 | Acesso interno, dados pessoais de servidores |
| **P√∫blico** | 2 | Acesso p√∫blico, transpar√™ncia administrativa |

### Esquema de Dados

```json
{
  "_id": "ObjectID",
  "texto": "String - Conte√∫do textual do documento",
  "classificacao_acesso": "Integer - R√≥tulo (0, 1, 2)",
  "fonte": "String - 'reformula√ß√£o' ou 'sint√©tico'"
}
```

## üöÄ Instala√ß√£o

### Pr√©-requisitos

- Python 3.8+
- MongoDB
- Chaves de API do Google Gemini

### Configura√ß√£o

1. **Clone o reposit√≥rio:**
```bash
git clone https://github.com/emerson-diego/leia.git
cd leia
```

2. **Instale as depend√™ncias:**
```bash
pip install -r requirements.txt
```

3. **Configure as vari√°veis de ambiente:**
Crie um arquivo `.env` na pasta `projeto/` com:

```env
# MongoDB
MONGO_USER=seu_usuario
MONGO_PASS=sua_senha
MONGO_HOST=localhost
MONGO_PORT=27017

# Google Gemini API Keys
GEMINI_API_KEY=sua_chave_principal
GEMINI_API_KEY_4=chave_adicional_1
GEMINI_API_KEY_5=chave_adicional_2
# ... adicione mais chaves conforme necess√°rio
```

## üìÅ Estrutura do Projeto

```
leia/
‚îú‚îÄ‚îÄ dataset_final/
‚îÇ   ‚îî‚îÄ‚îÄ dataset_treinamento.chunks_treinamento.json  # Dataset final
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ gemini_classificacao_utils.py     # Utilit√°rios de classifica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ sintetizador_de_chunks.py         # Gera√ß√£o de dados sint√©ticos
‚îÇ   ‚îú‚îÄ‚îÄ aumentador_dataset_sigiloso.py    # Aumento da classe sigilosa
‚îÇ   ‚îî‚îÄ‚îÄ rotular_chunks_gemini.py          # Rotulagem autom√°tica
‚îî‚îÄ‚îÄ README.md
```

## üîß Pipeline de Constru√ß√£o

O dataset LEIA foi constru√≠do atrav√©s de um pipeline de 9 etapas:

### 1. Coleta de Dados
- Extra√ß√£o de documentos p√∫blicos do TRT-13
- Foco em documentos j√° classificados como p√∫blicos
- Armazenamento em MongoDB

### 2. Pr√©-processamento
- Extra√ß√£o de texto de PDFs (OCR quando necess√°rio)
- Anonimiza√ß√£o com API Shiva (NER + Presidio + Regex)
- Segmenta√ß√£o em chunks de ~200 palavras

### 3. Enriquecimento
- **Reformula√ß√£o Contextual**: Reescreve textos preservando significado
- **Gera√ß√£o Sint√©tica**: Cria novos exemplos para classe minorit√°ria

### 4. Rotulagem e Valida√ß√£o
- Classifica√ß√£o autom√°tica com Gemini 2.5 Flash
- Valida√ß√£o humana em amostra de 10%
- √çndice Kappa de Cohen: 0.512 (concord√¢ncia moderada)

### 5. Balanceamento
- Subamostragem inteligente das classes majorit√°rias
- Preserva√ß√£o dos exemplos com maior confian√ßa

## üõ†Ô∏è Scripts Dispon√≠veis

### `gemini_classificacao_utils.py`
Utilit√°rios para classifica√ß√£o autom√°tica de documentos usando a API Gemini.

**Funcionalidades:**
- Classifica√ß√£o de chunks de texto
- Gerenciamento de m√∫ltiplas chaves de API
- Tratamento de erros e rate limiting

**Uso:**
```python
from scripts.gemini_classificacao_utils import classificar_chunk_gemini

classificacao, justificativa, confianca, modelo, versao = classificar_chunk_gemini(
    texto, gemini_keys, gemini_key_names, model
)
```

### `sintetizador_de_chunks.py`
Gera vers√µes sint√©ticas de documentos atrav√©s de reformula√ß√£o contextual.

**Funcionalidades:**
- Processamento em lotes para efici√™ncia
- Substitui√ß√£o de placeholders anonimizados
- Preserva√ß√£o de contexto e jarg√£o t√©cnico

**Uso:**
```bash
python scripts/sintetizador_de_chunks.py
```

### `aumentador_dataset_sigiloso.py`
Cria dados sint√©ticos espec√≠ficos para a classe "Sigiloso".

**Funcionalidades:**
- Gera√ß√£o de documentos m√©dicos, jur√≠dicos e de RH
- Diferentes n√≠veis de sigilo (Alto e M√©dio)
- Transforma√ß√£o conceitual de documentos de inspira√ß√£o

**Uso:**
```bash
python scripts/aumentador_dataset_sigiloso.py
```

### `rotular_chunks_gemini.py`
Script para transferir dados classificados para o dataset final.

**Funcionalidades:**
- Sele√ß√£o dos melhores exemplos por confian√ßa
- Mapeamento de fontes (reformula√ß√£o/sint√©tico)
- Prepara√ß√£o para treinamento

## üìà Estat√≠sticas do Dataset

| M√©trica | Valor |
|---------|-------|
| **Total de Registros** | 6.000 |
| **Registros por Classe** | 2.000 |
| **Comprimento M√©dio** | ~200 palavras |
| **Formato** | JSON |
| **Tamanho do Arquivo** | ~6.8MB |

## üéØ Aplica√ß√µes

### Treinamento de Modelos
```python
import json
import pandas as pd

# Carregar o dataset
with open('dataset_final/dataset_treinamento.chunks_treinamento.json', 'r') as f:
    data = json.load(f)

# Converter para DataFrame
df = pd.DataFrame(data)

# Preparar para treinamento
X = df['texto'].values
y = df['classificacao_acesso'].values
```

### An√°lise de Risco
- Identifica√ß√£o de padr√µes em documentos propensos a erros
- Auditoria de conformidade documental
- Desenvolvimento de pol√≠ticas de governan√ßa

## üîí Privacidade e Seguran√ßa

### Prote√ß√µes Implementadas

1. **Anonimiza√ß√£o Completa**: Remo√ß√£o de PIIs (CPF, CNPJ, nomes)
2. **Dados Sint√©ticos**: 100% dos textos s√£o fict√≠cios
3. **Reformula√ß√£o Contextual**: Desvincula√ß√£o de formula√ß√µes originais
4. **Valida√ß√£o Humana**: Verifica√ß√£o de qualidade e privacidade

### Conformidade Legal

- ‚úÖ Lei Geral de Prote√ß√£o de Dados (LGPD)
- ‚úÖ Lei de Acesso √† Informa√ß√£o (LAI)
- ‚úÖ Princ√≠pios de ci√™ncia aberta
- ‚úÖ Licen√ßa Creative Commons (CC BY-SA 4.0)

## üìö Cita√ß√£o

Se voc√™ usar o dataset LEIA em sua pesquisa, cite:

```bibtex
@article{araujo2024leia,
  title={LEIA: Um Dataset Curado e Enriquecido para Classifica√ß√£o de Conformidade Documental no Setor P√∫blico Brasileiro},
  author={Araujo, Emerson Diego da Costa and Pessoa, Diego Ernesto Rosa},
  journal={[Nome do Peri√≥dico]},
  year={2024},
  publisher={[Editora]}
}
```

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0).

## üë• Autores

- **Emerson Diego da Costa Araujo** - [emerson.diego@academico.ifpb.edu.br](mailto:emerson.diego@academico.ifpb.edu.br)
- **Diego Ernesto Rosa Pessoa** - [diego.pessoa@ifpb.edu.br](mailto:diego.pessoa@ifpb.edu.br)

**Institui√ß√£o:** Instituto Federal da Para√≠ba (IFPB)

## üìû Contato

Para d√∫vidas, sugest√µes ou problemas:

- **Email:** emerson.diego@academico.ifpb.edu.br
- **Issues:** [GitHub Issues](https://github.com/emerson-diego/leia/issues)
- **Reposit√≥rio:** [https://github.com/emerson-diego/leia](https://github.com/emerson-diego/leia)

## üîÆ Trabalhos Futuros

- [ ] Dataset din√¢mico com atualiza√ß√µes cont√≠nuas
- [ ] Expans√£o para outros √≥rg√£os p√∫blicos
- [ ] Modelos pr√©-treinados espec√≠ficos para o dom√≠nio
- [ ] Interface web para classifica√ß√£o interativa
- [ ] Integra√ß√£o com sistemas de gest√£o documental

---

**Nota:** Este dataset foi desenvolvido para fins de pesquisa e desenvolvimento de tecnologias de IA no setor p√∫blico brasileiro, sempre respeitando a privacidade e a conformidade legal. 