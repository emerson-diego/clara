# DocumentaÃ§Ã£o TÃ©cnica - Dataset CLARA

## ğŸ“‹ SumÃ¡rio Executivo

O CLARA (*ClassificaÃ§Ã£o Legal de Arquivos e Registros Administrativos*) Ã© um dataset pÃºblico para classificaÃ§Ã£o de conformidade documental no setor pÃºblico brasileiro. Esta documentaÃ§Ã£o tÃ©cnica detalha a arquitetura, metodologia e implementaÃ§Ã£o do projeto.

## ğŸ—ï¸ Arquitetura do Sistema

### VisÃ£o Geral da Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Coleta de     â”‚    â”‚  ExtraÃ§Ã£o de    â”‚    â”‚  AnonimizaÃ§Ã£o   â”‚
â”‚   Dados         â”‚â”€â”€â”€â–¶â”‚  Texto e        â”‚â”€â”€â”€â–¶â”‚  e              â”‚
â”‚   (TRT-13)      â”‚    â”‚  Metadados      â”‚    â”‚  SegmentaÃ§Ã£o    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset       â”‚â—€â”€â”€â”€â”‚  Rotulagem      â”‚â—€â”€â”€â”€â”‚  Enriquecimento â”‚
â”‚   Final         â”‚    â”‚  e ValidaÃ§Ã£o    â”‚    â”‚  (ReformulaÃ§Ã£o  â”‚
â”‚   (JSON)        â”‚    â”‚  (10%)          â”‚    â”‚  + SintÃ©tica)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principais

1. **Sistema de Coleta**: ExtraÃ§Ã£o de documentos do TRT-13 (PROAD-OUV)
2. **Pipeline de Processamento**: AnonimizaÃ§Ã£o e segmentaÃ§Ã£o
3. **Sistema de Enriquecimento**: ReformulaÃ§Ã£o contextual e geraÃ§Ã£o sintÃ©tica
4. **Sistema de ClassificaÃ§Ã£o**: Rotulagem semiautomÃ¡tica com LLMs
5. **Sistema de ValidaÃ§Ã£o**: Curadoria humana (10% dos registros)
6. **Sistema de Armazenamento**: MongoDB (coleÃ§Ã£o `chunks_treinamento`)

## ğŸ”§ Metodologia de ConstruÃ§Ã£o

### Pipeline de 9 Etapas

#### Etapa 1: Coleta de Dados
- **Fonte**: Sistema PROAD-OUV do TRT-13
- **CritÃ©rio**: Apenas documentos classificados como "pÃºblicos"
- **Formato**: Metadados + conteÃºdo binÃ¡rio (BLOB)
- **Armazenamento**: Oracle â†’ MongoDB

#### Etapa 2: ExtraÃ§Ã£o de Metadados
- **Captura**: InformaÃ§Ãµes estruturadas (assunto, data, classificaÃ§Ã£o)
- **Armazenamento**: MongoDB para processamento modular
- **Rastreabilidade**: Cada etapa gera nova coleÃ§Ã£o

#### Etapa 3: ExtraÃ§Ã£o de Texto
- **Tecnologia**: PyPDF2 + OCR (quando necessÃ¡rio)
- **Abordagem**: Condicional (texto nativo â†’ OCR se baixa qualidade)
- **Formato**: Exclusivamente PDFs

#### Etapa 4: AnonimizaÃ§Ã£o
- **API**: Shiva (interna do TRT-13)
- **TÃ©cnicas**:
  - NER baseado em Transformer
  - Microsoft Presidio
  - ExpressÃµes regulares para identificadores brasileiros
- **SubstituiÃ§Ã£o**: Placeholders genÃ©ricos (`[NOME]`, `[CPF]`, etc.)

#### Etapa 5: SegmentaÃ§Ã£o
- **Tamanho**: ~200 palavras por chunk
- **EstratÃ©gia**: SegmentaÃ§Ã£o nÃ£o sobreposta
- **Justificativa**: Compatibilidade com modelos Transformer (512 tokens)

#### Etapa 6: ReformulaÃ§Ã£o Contextual
- **Modelo**: Gemini 2.5 Flash
- **Objetivo**: Camada adicional de privacidade + desvinculaÃ§Ã£o das formulaÃ§Ãµes originais
- **PreservaÃ§Ã£o**: Significado e contexto original
- **AlteraÃ§Ã£o**: Estrutura de frases e vocabulÃ¡rio

#### Etapa 7: GeraÃ§Ã£o SintÃ©tica
- **Modelo**: Gemini 2.5 Flash
- **Foco**: Classe minoritÃ¡ria (Sigiloso)
- **EstratÃ©gia**: CriaÃ§Ã£o de dados (Data Creation)
- **Resultado**: 1.500 trechos adicionais
- **Tipos**: Documentos mÃ©dicos, jurÃ­dicos, de RH

#### Etapa 8: Rotulagem SemiautomÃ¡tica
- **Modelo**: Gemini 2.5 Flash (classificaÃ§Ã£o zero-shot)
- **SaÃ­da**: Classe + justificativa + confianÃ§a
- **ValidaÃ§Ã£o**: Ãndice Kappa de Cohen = 0.865 ("quase perfeito")
- **Amostra validada**: 10% dos registros

#### Etapa 9: Balanceamento Final
- **EstratÃ©gia**: Subamostragem inteligente
- **CritÃ©rio**: Maior escore de confianÃ§a
- **Resultado**: ~2.000 registros por classe (~6.000 total)

## ğŸ“Š EspecificaÃ§Ãµes TÃ©cnicas

### Estrutura de Dados MongoDB

| CaracterÃ­stica | EspecificaÃ§Ã£o |
|----------------|---------------|
| **Banco de Dados** | `dataset_treinamento` |
| **ColeÃ§Ã£o Principal** | `chunks_treinamento` |
| **Encoding** | UTF-8 |
| **Classes** | 3 (0: Sigiloso, 1: Interno, 2: PÃºblico) |
| **Comprimento MÃ©dio** | ~200 palavras |

### Esquema de Dados - chunks_treinamento

```json
{
  "_id": "ObjectId",
  "texto": "string",
  "classificacao_acesso": "integer (0, 1, 2)",
  "fonte": "string"
}
```

### Classes de ClassificaÃ§Ã£o

| CÃ³digo | Nome | DescriÃ§Ã£o | CritÃ©rios |
|--------|------|-----------|-----------|
| **0** | Sigiloso | Acesso restrito | Processos de investigaÃ§Ã£o, dados sensÃ­veis, sigilo legal |
| **1** | Interno | Acesso interno | Atos preparatÃ³rios, dados pessoais de servidores |
| **2** | PÃºblico | Acesso pÃºblico | Atos finais, interesse geral, transparÃªncia |

## ğŸ› ï¸ ImplementaÃ§Ã£o dos Scripts

### 1. `gemini_classificacao_utils.py`

#### Funcionalidades Principais
- **ClassificaÃ§Ã£o SemiautomÃ¡tica**: AnÃ¡lise de conformidade documental com LGPD/LAI
- **Parsing Estruturado**: ExtraÃ§Ã£o de classificaÃ§Ã£o (0-2), justificativa e confianÃ§a
- **IntegraÃ§Ã£o MongoDB**: Processamento de chunks pendentes na coleÃ§Ã£o
- **Logging Detalhado**: Monitoramento de performance e debug
- **Zero-shot Classification**: Uso do Gemini 2.5 Flash

#### Prompt de ClassificaÃ§Ã£o
```
AnÃ¡lise de Conformidade Documental - Contexto Administrativo Brasileiro
PRINCÃPIOS-CHAVE:
1. ATO PREPARATÃ“RIO vs. ATO FINAL
2. INVESTIGAÃ‡ÃƒO E APURAÃ‡ÃƒO = SIGILO
3. DADO PESSOAL EM CONTEXTO ADMINISTRATIVO
4. TRANSPARÃŠNCIA vs. PRIVACIDADE (LAI/LGPD)
```

### 2. `sintetizador_de_chunks.py`

#### Funcionalidades Principais
- **ReformulaÃ§Ã£o Contextual**: Reescrita completa de textos preservando significado
- **SubstituiÃ§Ã£o de Placeholders**: Dados fictÃ­cios realistas e plausÃ­veis
- **PreservaÃ§Ã£o de Contexto**: JargÃ£o tÃ©cnico e nÃ­vel de sigilo mantidos
- **Controle de Qualidade**: Escore de confianÃ§a (0.0-1.0)
- **Limite de Tamanho**: MÃ¡ximo 200 palavras por texto

#### ConfiguraÃ§Ãµes
- **Modelo**: Gemini 2.5 Flash
- **TÃ©cnica**: ReformulaÃ§Ã£o semÃ¢ntica
- **Objetivo**: Camada adicional de privacidade

### 3. `aumentador_dataset_sigiloso.py`

#### Funcionalidades Principais
- **GeraÃ§Ã£o SintÃ©tica**: CriaÃ§Ã£o de dados para classe minoritÃ¡ria
- **Template Estruturado**: Prompt com persona de especialistas (Corregedor-Geral + DPO)
- **Processo em 4 Etapas**: Semente conceitual â†’ CombinaÃ§Ã£o de eixos â†’ TransformaÃ§Ã£o â†’ GeraÃ§Ã£o
- **Controle de Autenticidade**: JargÃ£o tÃ©cnico, normas, cÃ³digos especÃ­ficos
- **Resultado**: 1.500 trechos adicionais para classe 'Sigiloso'

#### Tipos de Documentos Gerados
- **LicenÃ§as mÃ©dicas sigilosas**
- **Processos disciplinares**
- **Documentos com dados sensÃ­veis LGPD**
- **InvestigaÃ§Ãµes internas**

### 4. `rotular_chunks_gemini.py`

#### Funcionalidades Principais
- **Rotulagem Zero-shot**: Uso do Gemini 2.5 Flash
- **SaÃ­da Estruturada**: Classe + justificativa + confianÃ§a
- **Processamento em Lote**: Chunks pendentes no MongoDB
- **Controle de Qualidade**: ValidaÃ§Ã£o baseada em confianÃ§a
- **IntegraÃ§Ã£o**: ColeÃ§Ã£o `chunks_treinamento`

## ğŸ”’ SeguranÃ§a e Privacidade

### ProteÃ§Ãµes Implementadas

1. **AnonimizaÃ§Ã£o Completa**
   - NER com Transformer
   - Microsoft Presidio
   - Regex para identificadores brasileiros

2. **ReformulaÃ§Ã£o Contextual**
   - 100% dos textos reescritos
   - DesvinculaÃ§Ã£o das formulaÃ§Ãµes originais
   - PreservaÃ§Ã£o apenas do significado

3. **Dados SintÃ©ticos**
   - GeraÃ§Ã£o artificial para classe minoritÃ¡ria
   - Nenhum documento original no corpus final

4. **ValidaÃ§Ã£o Humana**
   - VerificaÃ§Ã£o de qualidade (10% dos registros)
   - ConfirmaÃ§Ã£o de privacidade
   - Sistema web especializado

### Conformidade Legal

- âœ… **LGPD**: Lei Geral de ProteÃ§Ã£o de Dados
- âœ… **LAI**: Lei de Acesso Ã  InformaÃ§Ã£o
- âœ… **CiÃªncia Aberta**: LicenÃ§a Creative Commons (CC BY-SA 4.0)
- âœ… **TransparÃªncia**: Metodologia documentada

## ğŸ“ˆ MÃ©tricas de Qualidade

### ValidaÃ§Ã£o SemiautomÃ¡tica
- **Ãndice Kappa de Cohen**: 0.865 ("quase perfeito")
- **Modelo**: Gemini 2.5 Flash
- **AcurÃ¡cia**: ~91%
- **MÃ©todo**: ClassificaÃ§Ã£o zero-shot

### ValidaÃ§Ã£o Humana
- **Amostra**: 10% dos registros
- **CritÃ©rio**: SeleÃ§Ã£o aleatÃ³ria
- **ResponsÃ¡vel**: Pesquisador especialista
- **Sistema**: Interface web customizada

### ValidaÃ§Ã£o Experimental
- **Modelo**: Legal-BERT (fine-tuning)
- **F1-Score**: 0.94
- **DivisÃ£o**: 80% treino, 10% validaÃ§Ã£o, 10% teste
- **Performance**: Equilibrada entre as 3 classes

## ğŸš€ Performance e Escalabilidade

### Resultados do Pipeline

| MÃ©trica | Valor |
|---------|-------|
| **Corpus Inicial** | Documentos pÃºblicos do TRT-13 |
| **Corpus ApÃ³s Enriquecimento** | 11.478 trechos |
| **Corpus Final (Balanceado)** | ~6.000 trechos |
| **DistribuiÃ§Ã£o Final** | 2.000 registros por classe |
| **Taxa de ValidaÃ§Ã£o** | 10% validaÃ§Ã£o humana |

### EstatÃ­sticas do Dataset Final

- **Classe Sigiloso (0)**: ~2.000 registros
- **Classe Interno (1)**: ~2.000 registros  
- **Classe PÃºblico (2)**: ~2.000 registros
- **Origem**: ReformulaÃ§Ã£o contextual + geraÃ§Ã£o sintÃ©tica
- **Compatibilidade**: Modelos Transformer (BERT, RoBERTa, Legal-BERT)

## ğŸ”§ ConfiguraÃ§Ã£o e Deploy

### Requisitos de Sistema

- **Python**: 3.8+
- **MongoDB**: 4.4+
- **Google Chrome**: Para automaÃ§Ã£o web
- **RAM**: 8GB+
- **Disco**: 20GB+
- **GPU**: Recomendada para fine-tuning

### ConfiguraÃ§Ã£o de Ambiente

```bash
# InstalaÃ§Ã£o de dependÃªncias
pip install -r requirements.txt

# ConfiguraÃ§Ã£o do MongoDB
sudo systemctl start mongod
sudo systemctl enable mongod

# ConfiguraÃ§Ã£o das variÃ¡veis de ambiente
cp .env.example .env
# Editar .env com suas credenciais Gemini
```

### Sistema de ValidaÃ§Ã£o Humana

```python
# Interface web para curadoria
# Componentes:
# - ID do Documento
# - Fonte (reformulaÃ§Ã£o/sintÃ©tico)
# - Texto completo
# - ClassificaÃ§Ã£o original (LLM)
# - ConfianÃ§a da classificaÃ§Ã£o
# - Justificativa da IA (XAI)
# - BotÃµes de classificaÃ§Ã£o final
```

## ğŸ§ª ValidaÃ§Ã£o Experimental

### ConfiguraÃ§Ã£o do Experimento

```python
# Modelo: Legal-BERT
# Dataset: CLARA (~6.000 registros)
# DivisÃ£o: 80% treino, 10% validaÃ§Ã£o, 10% teste
# Ã‰pocas: 3
# Batch size: 16
# Taxa de aprendizado: 2 Ã— 10^-5
# Hardware: GPU NVIDIA A100
```

### Resultados por Classe

| Classe | PrecisÃ£o | RevocaÃ§Ã£o | F1-Score | Suporte |
|--------|----------|-----------|----------|---------|
| **Sigiloso (0)** | 0.95 | 0.93 | 0.94 | 200 |
| **Interno (1)** | 0.92 | 0.94 | 0.93 | 200 |
| **PÃºblico (2)** | 0.94 | 0.94 | 0.94 | 200 |
| **Macro Avg** | - | - | **0.94** | 600 |

## ğŸ“š ReferÃªncias TÃ©cnicas

### Bibliotecas Utilizadas

- **google-generativeai**: API do Google Gemini 2.5 Flash
- **pymongo**: Cliente MongoDB
- **python-dotenv**: Gerenciamento de variÃ¡veis de ambiente
- **transformers**: Hugging Face Transformers (Legal-BERT)
- **torch**: PyTorch para fine-tuning
- **pandas**: ManipulaÃ§Ã£o de dados
- **sklearn**: MÃ©tricas de avaliaÃ§Ã£o

### APIs Externas

- **Google Gemini API**: ReformulaÃ§Ã£o contextual e classificaÃ§Ã£o
- **MongoDB**: Armazenamento de dados (`chunks_treinamento`)
- **API Shiva**: AnonimizaÃ§Ã£o (interna do TRT-13)

### Modelos Utilizados

- **Gemini 2.5 Flash**: ReformulaÃ§Ã£o, geraÃ§Ã£o sintÃ©tica e classificaÃ§Ã£o
- **Legal-BERT**: ValidaÃ§Ã£o experimental (fine-tuning)
- **Transformer NER**: AnonimizaÃ§Ã£o (via API Shiva)
- **Microsoft Presidio**: DetecÃ§Ã£o de PIIs

## ğŸ”® Roadmap TÃ©cnico

### Melhorias Planejadas

- [ ] **Dataset DinÃ¢mico**: AtualizaÃ§Ãµes contÃ­nuas
- [ ] **ExpansÃ£o Interinstitucional**: Outros Ã³rgÃ£os pÃºblicos
- [ ] **Modelos Especializados**: Fine-tuning para domÃ­nio especÃ­fico
- [ ] **Interface Web**: ClassificaÃ§Ã£o interativa
- [ ] **API REST**: ServiÃ§o de classificaÃ§Ã£o em tempo real

### AplicaÃ§Ãµes Futuras

- [ ] **AnÃ¡lise de Risco**: IdentificaÃ§Ã£o de padrÃµes de erro
- [ ] **Auditoria AutomÃ¡tica**: VerificaÃ§Ã£o de conformidade
- [ ] **GovernanÃ§a de Dados**: PolÃ­ticas automatizadas
- [ ] **Treinamento ContÃ­nuo**: Aprendizado incremental

---

**Nota**: Esta documentaÃ§Ã£o tÃ©cnica reflete a metodologia descrita no artigo cientÃ­fico "CLARA: Um Dataset Validado e Enriquecido para ClassificaÃ§Ã£o de Conformidade Documental no Setor PÃºblico Brasileiro". Para a versÃ£o mais recente, consulte o repositÃ³rio oficial. 